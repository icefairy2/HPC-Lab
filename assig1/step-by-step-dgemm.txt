
- original implementation performance ~2 Gflops

- optimizations 1 - 5 didn't change it

- opt. 6 - 9 (using normal registers and pointers): performance went up a bit. I think it was around 4 Gflops

- switch to 4x4 block

- not much change until using vector registers

- using _m128d: ~4 Gflops
  _m256d: ~6-7 Gflops i think
  (KNL only legacy supports these)
  
- Switch to _m512d registers computing 4x8 block : 10 or 15 Gflops (not sure anymore)
  KNL can execute 2 512 bit instructions per clock (2 VPUs per core)

- changing it to 8x8 blocks: ~20 Gflops 

- unrolling the inner loop (computing 4 rows instead of 1): ~22-23 Gflops 
  I did this because it is a step here http://apfel.mathematik.uni-ulm.de/~lehn/sghpc/gemm/page04/index.html
  Apparantly the compiler wasn't smart enough to do this on its own
  
- unrolling with 8 steps per loop run decreases performance to ~15 Gflops 

- added blocking to maintain performance for larger matrices (optimization 11)
  now larger matrices are computed using smaller blocks that fit in L2 cache
  
- packing A and B doesn't work
  maybe Matrix too small 