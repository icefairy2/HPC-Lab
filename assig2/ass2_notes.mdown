# Assignment 2
## Part 1:
### Shared memory pi-calculation
#### 1. Serial implementation
Code that integrates function 1/(1+x^2) over [0, 1].
```C++
//function to be integrated
double phi(double x) {
    return 1 / (1 + x*x);
}

int main(int argc, char** argv)
{
    int i;
    double h, y, sum;
    //number of partitions
    long n = 100000000;

    h = 1. / n;

    sum = 0;

    for (i = 0; i <= n; i++)
    {
        //calculate function value at current partition
        y = phi(i*h);
        //add current function value to sum
        sum += y;
    }
    sum *= 4. * h;
	//result of integration is in sum
	
    return 0;
}
```

#### 2. Parralelized application
With the critical directive, the for loop becomes:
```C++
#pragma omp parallel for private(y), shared(sum) 
    for (i = 0; i <= n; i++)
    {
        //calculate function value at current partition
        y = phi(i*h);
#pragma omp critical 
        //add current function value to sum
        sum += y;
    }
```
Using the reduction clause, the for loop looks like the following:
```C++
#pragma omp parallel for private(y), reduction(+: sum)
    for (i = 0; i <= n; i++)
    {
        //calculate function value at current partition
        y = phi(i*h);
        //add current function value to sum
        sum += y;
    }
```

#### 3. Scaling study
The time values are in microseconds.

##### Weak scaling using the critical directive
n = 25 000 000.

N/Nr of threads: n/16.
Time of execution (s): 17.931.

N/Nr of threads: 2n/32.
Time of execution (s): 36.884.

N/Nr of threads: 4n/64.
Time of execution (s): 76.407.

N/Nr of threads: 8n/128.
Time of execution (s): 149.951.

##### Strong scaling using the critical directive
n = 100 000 000.

Nr of threads: 16.
Time of execution (s): 73.772.

Nr of threads: 32.
Time of execution (s): 73.902.

Nr of threads: 64.
Time of execution (s): 77.451.

Nr of threads: 128.
Time of execution (s): 78.451.

Because every single thread has to access the critical zone sequentially, the time of execution slows down by using the critical directive.


##### Weak scaling using the reduction clause
n = 250 000 000.

N/Nr of threads: n/16.
Time of execution (s): 0.176.

N/Nr of threads: 2n/32.
Time of execution (s): 0.181.

N/Nr of threads: 4n/64.
Time of execution (s): 0.202.

N/Nr of threads: 8n/128.
Time of execution (s): 0.302.

##### Strong scaling using the reduction clause
n = 1 000 000 000.

Nr of threads: 16.
Time of execution (s): 0.610.

Nr of threads: 32.
Time of execution (s): 0.325.

Nr of threads: 64.
Time of execution (s): 0.196.

Nr of threads: 128.
Time of execution (s): 0.188.

###Conclusion
Using the critical directive kills performance because threads have to access the critical section one after another.
Parallelizing with the reduction clause leads to faster execution once more threads are introduced.

Strong scaling shows that if the problem is big enough adding more threads to parallelize it works up to a certain point. It will have diminishing returns once the problem chunks are so small that the overhead of adding more threads doesnâ€™t help anymore.


## Part 2